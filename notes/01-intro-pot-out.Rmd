---
title: | 
    | Introduction and Potential Outcomes
header-includes:
  - \usepackage{datetime}
  - \usepackage{natbib}
  - \usepackage{amsmath}
  - \usepackage{wasysym}
date: "22 July 2019"
author: Ryan T. Moore
output:
  beamer_presentation:
    slide_level: 2
    toc: true
    fonttheme: serif
    includes:
      in_header: zzz_beamer_header.tex
  pdf_document:
    fig_caption: true
    number_sections: true
    urlcolor: blue
link-citations: yes 
---
  
```{r knitr options, echo=FALSE, warning=FALSE}
# Encoding required for proper knitr rendering
options(encoding = "native.enc")
```

```{r enviro, warning = FALSE, results = 'hide', echo = FALSE, message = FALSE}
####  Computing Environment

## Load libraries:
library(tidyr) 
library(dplyr)
library(ggplot2)
library(xtable)
library(coefplot)
library(knitr)
library(png)
library(grid)
library(gridExtra)
library(readr)
library(modelr)
library(tibble)
library(devtools)
library(forcats)
library(stringr)
library(magrittr)
library(purrr)

## RTM directory:
#setwd("~/Documents/github/r-data-science/notes/")
#opts_knit$set(root.dir = "~/Desktop/")

```

# Welcome

<!-- Include screenshot: -->
<!-- ```{r fig.width=4.4, echo=FALSE} -->
<!-- img <- readPNG("figs/viz-practice.png") -->
<!-- grid.raster(img) -->
<!-- ``` -->

<!-- Include a pdf fig: -->

<!-- \begin{center} -->
<!-- \includegraphics[height=3.1in]{figs/viz-facet-MedNoneRace.pdf} -->
<!-- \end{center} -->

## About Me

\Large

- Associate Prof of Government, American University
- Senior Social Scientist, The Lab @ DC 
- Research agenda: political methodology, causal inference, experimental design

## The Course: Learning Objectives

\large

>- Identify causal effects using the potential outcomes framework
>- Perform design-based inference for randomized experiments
>- Create and analyze variety of randomized designs, including for blocked, 
conjoint, list, and multiarm bandit experiments
<!-- >- Identify appropriate designs for causal inference in observational data,  -->
<!-- implement them, and interpret them; these include matching, instrumental  -->
<!-- variables, regression discontinuities, and synthetic controls -->
<!-- >- Assess the sensitivity of estimates to unmeasured confounders -->
>- Estimate mediation effects and assess their sensitivity

>- (Walk through syllabus)


# What is Causal Inference?

## What is Causal Inference?

\LARGE

\begin{center}
``What caused the 9/11 attacks?''
\end{center}

\begin{center}
vs.
\end{center}

\begin{center}
``What is the effect of foreign policy $X$ on domestic terror attacks?''
\end{center}


## Example: Canvassing and Program Enrollment

\large
Suppose we ask, ``Would a canvassing policy increase enrollment in a health insurance program?'' \pause 

\vspace{2mm}

\begin{center}
\begin{tabular}{ccc}
Citizen & Canvassed? & Enrolled? \\ \hline
1 & Yes & Yes \\
2 & Yes & Yes \\
3 & No & No \\
4 & No & No
\end{tabular}
\end{center} \pause 

\vspace{2mm}

>- What fraction enroll under canvassing vs. no canvassing?  
>- $\frac{2}{2} - \frac{0}{2} = 1$
>- (For each person canvassed, expect 1 more enrollment.)


## Motivating Example: Canvassing and Enrollment

\Large
But, is it causal? \newline \pause 
\vspace{1mm}

What do we really want to know? \newline   \pause 
\vspace{1mm}

What would have happened under _other_ conditions? \newline  \pause 
\vspace{1mm}

Would canvassing actually _change_ anyone's enrollment? 


## Example: Canvassing and Enrollment

\large 
\begin{center}
\begin{tabular}{ccccc}
 & & Would Enroll if & Would Enroll if  & \\
Citizen & Canvass? & Canvass? & No Canvass? & Enroll \\ \hline
1 & Yes & \only<2->{Yes} & \only<6->{\alert{(Yes)}} &  Yes \\
2 & Yes & \only<3->{Yes} & \only<6->{\alert{(No)}} &  Yes \\
3 & No & \only<6->{\alert{(Yes)}} & \only<4->{No} &  No \\
4 & No &\only<6->{\alert{(No)}} & \only<5->{No} &  No
\end{tabular}
\end{center}

\vspace{5mm}

\pause 

\onslide<7->{What is the true causal effect of canvassing? \\}
\onslide<8->{What fraction enroll under canvass vs. no canvass? \\} 
\onslide<9->{What fraction change enrollment due to canvass?\\} 
\onslide<10->{$\frac{3}{4} - \frac{1}{4} = \frac{1}{2}$}


## Example: Canvassing and Enrollment

Empirical data consistent with *different* _unobserved_ outcomes:

\vspace{4mm}

\large
\begin{center}
\begin{tabular}{ccccc}
 & & Would Enroll if & Would Enroll if  & \\
Citizen & Canvass? & Canvass? & No Canvass? & Enroll \\ \hline
1 & Yes & Yes & \alert{(Yes)} &  Yes \\
2 & Yes & Yes & \alert{(No)} &  Yes \\
3 & No & \alert{(Yes)} & No &  No \\
4 & No & \alert{(Yes)} & No &  No
\end{tabular}
\end{center}

\pause 

\vspace{5mm}

What is the true causal effect of canvass? \newline  
What fraction enroll under canvass vs. no canvass? \newline  \pause 
$\frac{4}{4} - \frac{1}{4} = \frac{3}{4}$


## Example: Canvassing and Enrollment

\Large

\begin{center}
Well \ldots how do we know which?
\end{center}

\pause 

\vspace{5mm}

\begin{center}
We can never know.
\end{center}

***

\Large

\begin{center}
Can we know for one person?
\end{center}

\pause 

\vspace{5mm}

\begin{center}
We can never know.
\end{center}

***

\Large

\begin{center}
But I have some ideas.
\end{center}

\pause 

\vspace{5mm}

\begin{center}
We could not canvass, then canvass later.
\end{center}

\pause  

\vspace{5mm}

\begin{center}
We can never know.
\end{center}


***

\Large

\begin{center}
We can never observe both ``Canvassed'' and ``Not Canvassed'' for a unit.
\end{center}

\pause 

\vspace{5mm}

\begin{center}
We can never observe both \it{potential outcomes}.
\end{center}

\pause  

\vspace{5mm}

\begin{center}
We can never observe both the factual and the counterfactual.
\end{center}

\pause 

\vspace{5mm}

\begin{center}
We can never know.
\end{center}

## The Fundamental Problem of Causal Inference

\LARGE

\begin{center}
We can never observe more than one {\it potential outcome} for a given unit.
\end{center}


***

\LARGE

\begin{center}
So, how can we get a {\it causal} estimate?
\end{center}

\pause 

\vspace{6mm}

\begin{center}
We infer missing potential outcomes.
\end{center}

## Why didn't we recover truth?

\large

The problem with our naive estimate of effect:

>- "Canvass" group $\neq$ ``No Canvass'' group
>- The _potential outcomes_ help predict treatment conditn!

\pause 

\large
\begin{center}
\begin{tabular}{ccccc}
 & & Would Enroll if & Would Enroll if  & \\
Citizen & Canvass? & Canvass? & No Canvass? & Enroll \\ \hline
1 & Yes & Yes & \alert{(Yes)} &  Yes \\
2 & Yes & Yes & \alert{(No)} &  Yes \\
3 & No & \alert{(Yes)} & No &  No \\
4 & No &\alert{(No)} & No &  No
\end{tabular}
\end{center}

\pause 

\vspace{2mm}

Knowing whether would enroll under canvass _predicts_ whether canvassed!


## When comparing two groups **does** recover truth

\large

Here, potential outcomes do **not** help predict treatment:

\large
\begin{center}
\begin{tabular}{ccccc}
 & & Would Enroll if & Would Enroll if  & \\
Citizen & Canvass? & Canvass? & No Canvass? & Enroll \\ \hline
1 & Yes & Yes & \alert{(Yes)} &  Yes \\
2 & Yes & Yes & \alert{(No)} &  Yes \\
3 & No & \alert{(Yes)} & Yes &  Yes \\
4 & No &\alert{(Yes)} & No &  No
\end{tabular}
\end{center}

\pause 

Knowing whether enroll if canvass not predictive.

\pause 

>- What is the _true_ causal effect of canvass?  
>- $\frac{4}{4} - \frac{2}{4} = \frac{2}{4} = \frac{1}{2}$
>- What would we _observe_ as the effect of canvass?
>- $\frac{2}{2} - \frac{1}{2} = \frac{1}{2}$

\pause 

Good!



## When does comparing groups recover truth?


<!-- Formally, $Y_1, Y_0 \indep T$, or $E(Y_1, Y_0) = E(Y_1, Y_0 | T)$) -->

\Large

Neither _potential outcome_ should help predict treatment.  \newline  \pause 

\vspace{4mm}

(Note: _observed_ outcomes can predict treatment.)  \newline \pause

That's the goal!  \pause 

- Aspirin $\implies$ headache!  
- Canvass $\implies$ turnout!  
- Insurance $\implies$ health spending! 
- CBT $\implies$ remission! 




## When does comparing groups recover truth?

\large

How to ensure potential outcomes won't predict treatment?\newline  \pause 

\vspace{4mm}

How to _assign_ treatment so it won't predict pot. outcomes?


## When does comparing groups recover truth?

\large

Possible _assignment mechanisms_:  

\pause 

>- Let Citizens decide whether to get Canvass
>- (But, those who choose Canvass will Enroll anyway)
>- Let (expert) Party decide whom gets Canvass 
>- (But, Party will only Canvass those it will affect)
>- (You'll estimate a huge effect)
>- What if you \it{randomly} select whom gets Canvass?
>- (``Citizen got Canvass'' won't help guess pot. out.)


# The Potential Outcomes Model


## What is Causal Inference?

\large

>- ``Effects of causes''
>- Central definition for causal inference: ``a _well-defined_ treatment''.

\pause 

> The objective is to determine for some population of units \ldots the 'typical' causal effect of the [treatment vs. control conditions] on a dependent variable $Y$.
\hspace{80mm} ---Rubin (1974)

## What is Causal Inference?

\Large

>- Units must be ``potentially exposable'' to treatment
>- ``No causation without manipulation''
>- Timing of treatment: outcomes vs. covariates
>- Exclusivity of treatment
>- One study, one causal effect



## The Potential Outcomes Model: Ideas

\Large

>- _Unit_: a particular case at a point in time
>- _Treatment_: (putatively) causal variable of interest
>- _Potential outcome_: outcome that would obtain if unit were to receive tr condition
>- _Assignment mechanism_: means by which units come to be sorted into conditions

## The Potential Outcomes Model: Ideas

\Large

Stable Unit Treatment Value Assumption (SUTVA)

>- No versions of the treatment, varying in effectiveness
>- No interference between units


## The Potential Outcomes Model: Notation

\large

>- Units: index $i \in \{1, \ldots, 2n\}$
>- Binary treatment: $T_i \in \{0, 1\}$


>- Pot outcome for $i$ under $T_i = 1$: $Y_{i1}$ or $Y_i(1)$
>- Pot outcome for $i$ under $T_i = 0$: $Y_{i0}$ or $Y_i(0)$
>- For vector of $Y_{i1} \quad \forall i$, write $Y_1$


>- Observed outcome: $Y_i = Y_i(1)\cdot T_i + Y_i(0)\cdot (1 - T_i)$ 
>- (sometimes written $Y_i^{obs}$)
>- If $T_i = 1$, $Y_i = Y_i(1) \cdot 1 + Y_i(0)(1 - 1) = Y_i(1)$
>- If $T_i = 0$, $Y_i = Y_i(1) \cdot 0 + Y_i(0)(1 - 0) = Y_i(0)$

\pause 

\vspace{1mm}

The assignment mechanism _selects_ which potential outcome we observe.

## The Potential Outcomes Model: Estimands

Statistical language 

>* _parameter_: unknown numeric value characterizing feature of
  prob model (Greek; $\theta$, $\beta$) 
>* _statistic_: quantity calculable from observed data.  A function. (Roman)
>* _estimator_: statistic used to approximate/guess parameter ($\hat{\theta}$, $\hat{\beta}$)
>* _estimand_: the parameter an estimator attempts to estimate 
>* _estimate_: application of an estimator func to some obs data

\pause 
``The sample statistic $\bar{x}$ is an estimator of true mean
param $\mu$''.  

\pause 

$\mu$ is my estimand.  5.1 is my estimate.

## The Potential Outcomes Model: Estimands

\large

For $i$, individual treatment effect

$$\tau_i = Y_i(1) - Y_i(0)$$

>- True treatment effect?
>- Estimate?
>- Observable?

\pause 

\vspace{3mm}

\begin{center}
We can never know.
\end{center}

## Random variables and the Expectation

\large

_Random variable_ $X$ is a function mapping sample space to set of reals: $$X:\Omega \to \mathbb{R}$$ 

Random variables 

>- summarize outcome of probabilistic/stochastic trial
>- take numerical values.  

\pause 

E.g., 

>- Let $X =$ number of heads in 3 coin flips.  Is $X$ a random variable?
>- Let $Y$ be outcome of two coin flips, $Y \in \{HH, TH, HT, TT\}$.  Is $Y$ a random variable?


## Expectation of a Random Variable

The _expected value_ or _expectation_ of a random variable is mean of its outcomes, weighted by their probabilities.  For a discrete random variable, $$E(X) = \sum\limits_{i=1}^n x_ip(x_i)$$ For continuous random variable, $$E(X) = \int\limits_{-\infty}^{\infty} xp(x) dx$$

Expectation is **not** the sample mean from particular instantiation, a particular data set.  We use sample mean $\bar{x}$ to _estimate_ the expected value.

## Variance of a Random Variable

The _variance_ of a random variable is mean of outcomes' squared deviations from expectation, weighted by their probabilities:

\begin{eqnarray*}
V(X) & = & E[(X - E(X))^2]\\	
& = & E(X^2) - (E(X))^2	
\end{eqnarray*}


## Properties of Expectation

* $E(c) = c$ 
* $E(a+bX) = a+bE(X)$  
* $E(X+Y) = EX + EY$
* If $X$ and $Y$ indep., then $E(XY) = E(X)E(Y)$

## Properties of Variance

* $Var(X) = E(X-EX)^2$ 
* $Var(X) = E(X^2)-(EX)^2$ 
* $Var(c) = 0$
* $Var(Y|X) = E(Y^2|X)-(E(Y|X))^2$ 
* If $X$ and $Y$ indep., then $Var(X+Y) = Var(X)+Var(Y)$ 
* If $X$ and $Y$ indep, then $Var(X-Y) = Var(X)+Var(Y)$ 




## The Potential Outcomes Model: Estimands

>- Average treatment effect
	\begin{displaymath}
	ATE = E(Y_1 - Y_0) = E(Y_1) - E(Y_0)	
	\end{displaymath}

>- Average treatment effect for the treated
	\begin{displaymath}
	ATT = E(Y_1 | T = 1) - E(Y_0 | T = 1)
	\end{displaymath} 


## The Potential Outcomes Model: Estimands

The average treatment effect (ATE):

\begin{eqnarray*}
\overline{\tau} = \overline{TE} = ATE &\equiv & E(Y_{1} - Y_{0}) = \frac{1}{2n} \sum\limits_{i=1}^{2n} \left( Y_{i1} -
  Y_{i0} \right) \\ \pause 	
& = & E(Y_{1}) - E(Y_{0}) 	%\\ \pause
%& = & \frac{E(Y_1 | T_i =1 ) + E(Y_1 | T_i =0 )}{2} - \frac{E(Y_0 | T_i = 1) + E(Y_0 | T_i = 0)}{2}
\end{eqnarray*} 

\pause 

>- True?
>- Estimated?
>- Observable?


## The Potential Outcomes Model: Estimands

Something we can calculate:

>- If we know $(Y_1, Y_0)$ indep of $T$ 
<!-- (as random assignment of Tr promotes),  \pause -->

>- Then,

\pause 

\begin{eqnarray*}
E\left(Y_{1} \right) &=& E(Y_{1} | T = 1)\\ E\left(Y_{0} \right) & = & E(Y_{0} | T = 0)	
\end{eqnarray*}

\pause 

>- Then, can substitute 

\begin{eqnarray*}
	ATE & = & E(Y_{1}) - E(Y_{0}) \\
	& = & E(Y_1 | T = 1) - E(Y_0 | T = 0)
\end{eqnarray*}

\pause 

Observed diff in Tr and Co group means is unbiased est. of 
$\overline{TE}$!


## Common Assumptions, Null Hyp's in Causal Inference

\large

\begin{itemize}
\item Constant effect:

$$\tau_i = Y_{i1}-Y_{i0} = \tau \quad \forall i$$
\pause 

\item Null hypothesis of no average effect:

$$ATE = \overline{\tau} = 0$$

\pause 

\item Sharp null hypothesis of no effect: 

$$\tau_i = 0$$
\end{itemize}


## Compliance with Treatment Assignment

\note{Rubin's {\bf principal strata}}

\large

Sometimes, units don't follow assignment!

\vspace{3mm}

\begin{center}
\begin{tabular}{ccc}
Assigned Tr & Assigned Co & Type \\ \hline
Tr & Co 	&  Complier \\  \pause 
Tr & Tr & Always-taker \\ \pause 
Co & Co & Never-taker \\ \pause 
Co & Tr & Defier 
\end{tabular}
\end{center}



## Common Estimates under Noncompliance

Let $T_i$ be treatment _assigned_, $D_i$ be treatment _received_.

\pause 

>- Intent-to-treat effect
	\begin{eqnarray*}
	ITT &=& E(Y_1 | T = 1) - E(Y_0 | T = 0) \\
	&=& E(Y_1 | T = 1, D(T=1)) - E(Y_0 | T = 0, D(T=0)) 
	\end{eqnarray*} 
>- As-treated effect
	\begin{eqnarray*}
	ASTRE &=& E(Y_1 | D = 1) - E(Y_0 | D = 0)
	\end{eqnarray*}


# Computing 

## Computing

\large

>- R for simulations, estimation, graphics
>- RStudio, an IDE for R
<!-- >- RMarkdown for literate programming (papers with data analysis embedded) -->
<!-- >- Slack for course announcements, direct messages, etc. -->
<!-- >- Blackboard for distributing, collecting PS's -->


<!-- ## RMarkdown -->

<!-- \large -->

<!-- We will use RMarkdown, which uses \LaTeX\ for _literate programming_ -- integration of code and English that's output-ready  -->

<!-- \pause  -->

<!-- We will use new R package `tinytex` to convert RMarkdown to PDF files. -->


<!-- ## What RMarkdown Looks Like -->

<!-- ```{r fig.height=3.1, echo=FALSE} -->
<!-- img <- readPNG("figs/00-rmd_raw.png") -->
<!-- grid.raster(img) -->
<!-- ``` -->

<!-- ## What RMarkdown Output Looks Like -->

<!-- ```{r fig.height=3.1, echo=FALSE} -->
<!-- img <- readPNG("figs/00-rmd_render.png") -->
<!-- grid.raster(img) -->
<!-- ``` -->

***

\huge

\begin{center}
R Primer
\end{center}



## Functions

\Large
```{r, eval=FALSE}
function(arg1, arg2, ...){
  <the function code here...>
}
```
\pause 
```{r warning = FALSE}
sum(5, 2)
```
\pause 

```{r warning = FALSE}
mean(1:4)
``` 

## Functions 

\Large
```{r warning = FALSE, results = 'hide'}
nchar("greetings")
```
\pause 
```{r warning = FALSE, echo = FALSE}
nchar("greetings")
```
\pause 
```{r warning = FALSE, results = 'hide'}
ls()
```
\pause 
```{r warning = FALSE, echo = FALSE}
ls()
```

## A Useful Function: `c()`


\Large 

To concatenate objects into a vector, use `c()`:
\pause 
```{r}
c(1, 3, 8, 20)
```
\pause 
```{r warning = FALSE, results = 'hide'}
c("a", "merican", "u")
```
\pause 
```{r warning = FALSE, echo = FALSE}
c("a", "merican", "u")
```
\pause 

```{r warning = FALSE, results = 'hide'}
c(1, 2, "hello")
```
\pause 
```{r warning = FALSE, echo = FALSE}
c(1, 2, "hello")
```

## Functions' Arguments


\LARGE
What arguments does a function have? \pause

```{r warning = FALSE, results = 'hide'}
help(median)
args(median)
```
\pause 
```{r warning = FALSE, echo = FALSE}
args(median)
```

## Functions' Arguments

\large
```{r}
median(1:3)
```
\pause 

```{r warning = FALSE, results = 'hide'}
x <- c(1, 2, 3, NA) 
median(x)
```
\pause 
```{r warning = FALSE, echo = FALSE}
median(x)
```
\pause 

```{r warning = FALSE, results = 'hide'}
median(x, na.rm = TRUE)
```
\pause 
```{r warning = FALSE, echo = FALSE}
median(x, na.rm = TRUE)
```

## Functions' Arguments

\large

You can specify arguments in order or by name: \pause

```{r}
median(x, TRUE)
```
\pause 

```{r warning = FALSE}
median(na.rm = TRUE, x)
```
\pause 
```{r warning = FALSE}
median(TRUE, x)
```


## Some Useful Functions

\large
Managing the workspace:
```{r}
# Get the working directory ("Where am I?"):
getwd()
```
\pause 
```{r eval=FALSE, warning = FALSE}
# Set the working directory:
setwd("~/Desktop/")
```
\pause 
```{r warning = FALSE}
# List objects in working dir:
ls()
# Remove `x' from working dir:
rm(x)
# Remove everything from working dir:
rm(list = ls())
```


## Some Useful Functions

\Large
Making vectors:
```{r}
c(1, 2, 10)
```
\pause 
```{r warning = FALSE}
1:4
6:3
```

## Some Useful Functions

\Large

```{r warning = FALSE}
seq(from = 5, to = 30, by = 5)
```
\pause 
```{r warning = FALSE}
rep(c("a", "b"), 2)
```
\pause 
```{r warning = FALSE}
rep(c("a", "b"), each = 2)
```

## Extracting Elements from Vectors with `[`

\Large

```{r warning = FALSE}
x <- sample(0:1, size = 10, replace = TRUE)
```

\pause 

```{r warning = FALSE}
x
```

\pause 

```{r warning = FALSE}
x[3]
```

\pause 

```{r warning = FALSE}
x[3] <- 999
```

\pause 

```{r warning = FALSE}
x
```

## Some Useful Mathematical Functions

\Large

```{r}
5 + 2
5 - 2
5 * 2
5 / 2
```

## Some Useful Mathematical Functions

\Large
```{r warning = FALSE}
5 ^ 2
sqrt(25)
20 %% 3
```

## Some Useful Mathematical Functions and Values

\large
```{r}
pi
abs(-3)
exp(1)
log(exp(2))
sin(pi / 2)
```
\pause 

(See R Short Ref Card \ldots)



## Logicals

\large
```{r}
TRUE
```

```{r warning = FALSE}
FALSE
```
\pause 

```{r warning = FALSE, results = 'hide'}
TRUE == FALSE
```
\pause 
```{r warning = FALSE, echo = FALSE}
TRUE == FALSE
```

 
## Logicals

\large
```{r warning = FALSE, results = 'hide'}
c(1, 2) == c(1, 3)
```
\pause 
```{r warning = FALSE, echo = FALSE}
c(1, 2) == c(1, 3)
```
\pause 

```{r warning = FALSE, results = 'hide'}
c(1, 2) != c(1, 3)
```
\pause 
```{r warning = FALSE, echo = FALSE}
c(1, 2) != c(1, 3)
```
\pause 

```{r warning = FALSE, results = 'hide'}
c(1, 2) < c(1, 3)
```
\pause 
```{r warning = FALSE, echo = FALSE}
c(1, 2) < c(1, 3)
```

## Logicals

\large

```{r warning = FALSE}
c(1, 2) > c(1, 3)
c(1, 2) <= c(1, 3)
c(1, 2) >= c(1, 3)
```

## How to Write a New Function

\Large
```{r}
sumDiff <- function(num1 = 3, num2 = 5){
  
  sum <- num1 + num2
  
  diff <- num1 - num2
  
  return(c(sum, diff))
}
```
\pause 
Now, cut and paste function into R prompt.

\pause 
(R will tell you if syntax error.)


## My New Function

\Large

```{r warning = FALSE, results = 'hide'}
sumDiff()
```
\pause 
```{r warning = FALSE, echo = FALSE}
sumDiff()
```
\pause 

```{r warning = FALSE, results = 'hide'}
sumDiff(3, 5)
```
\pause 
```{r warning = FALSE, echo = FALSE}
sumDiff(3, 5)
```
\pause 

```{r warning = FALSE, results = 'hide'}
sumDiff(num2 = 5, num1 = 3)
```
\pause 
```{r warning = FALSE, echo = FALSE}
sumDiff(num2 = 5, num1 = 3)
```
\pause 

```{r warning = FALSE, results = 'hide'}
sumDiff(5, 3)
```
\pause 
```{r warning = FALSE, echo = FALSE}
sumDiff(5, 3)
```

## My New Function

\Large
```{r warning = FALSE, results = 'hide'}
sumDiff(2, 20)
```
\pause 
```{r warning = FALSE, echo = FALSE}
sumDiff(2, 20)
```
\pause 
```{r warning = FALSE, results = 'hide', eval=FALSE}
sumDiff(1, "yes")
```
\pause 
```{r warning = FALSE, echo = FALSE, error=TRUE}
sumDiff(1, "yes")
```





***

\huge

\begin{center}
Next:\\
Randomized Experiments, Estimation, and Inference

\end{center}

<!-- *** -->

<!-- \Huge -->

<!-- \begin{center} -->

<!-- Fun: Trivia\\ Tuesday, 8:30pm, Ward Lobby -->

<!-- \end{center} -->
